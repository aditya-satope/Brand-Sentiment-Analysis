{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-0.4.1.2.tar.gz (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 1.1 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.2.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.55.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (0.6)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.8)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.9.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.11.13)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-py3-none-any.whl size=103066 sha256=fe13a8089423aa94b7cb1f2ad4b5daefbd4b0d4faa113456e8a00669199859af\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/a2/db/5d9e7c4aa8dbd82718c202fb1bc7118c2d3bf0925af92943f2\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-0.4.1.2\n",
      "Collecting rouge\n",
      "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install -U rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r= [1,3, 23, 34, 63, 77, 106, 114, 115, 129, 134, 145, 160, 163, 165, 170, 175, 176, 183, 185, 188, 198, 245, 249, 256,260, 294, 332, 341, 355, 360, 363, 386, 392, 394, 398]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rouge import Rouge\n",
    "file=open('test-data/article_test_all_trans_eng.pkl','rb')\n",
    "\n",
    "\n",
    "test=pickle.load(file)\n",
    "file2=open('train-data/article_train_all_trans.pkl','rb')\n",
    "\n",
    "\n",
    "train=pickle.load(file2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "data_val=[]\n",
    "for i,j in zip(train['Text'],train['Headline']):\n",
    "    data_train.append([i,j])\n",
    "\n",
    "for i,j in zip(test['Text'],test['Headline']):\n",
    "    \n",
    "    data_val.append([i,j]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article(articles):\n",
    "    for article in articles:\n",
    "        article = re.sub(r\"http\\S+\", \"\", article)\n",
    "        article = re.sub(r\"www.\\S+\", \"\", article)\n",
    "        article = re.sub(r\"<\\S+\", \"\", article)\n",
    "        article = re.sub('\\n+', \" \",article)\n",
    "        article = article.strip()\n",
    "       \n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sign in Welcome! Log into your account your username', '#Paytm यूजर्स के लिए बड़ी खुशखबरी']\n",
      "['Subscription E-Commerce Market Stay up-to-date with Subscription E-Commerce Market research offered by HTF MI.  Check how key trends and emerging drivers are shaping this industry growth.  A New business research report released by HTF MI with title COVID-19 Outbreak-Global Subscription E-Commerce Market Study Forecast till 2026 .  This COVID-19 Outbreak-Global Subscription E-Commerce market report brings data for the estimated year 2020 and forecasted till 2026 in terms of both, value (US$ MN) and volume (MT).  The report also consists of forecast factors, macroeconomic factors, and a market outlook of the COVID-19 Outbreak- Subscription E-Commerce market.  The study is conducted by applying both top-down and bottom-up approaches and further iterative methods used to validate and size market estimation and trends of the COVID-19 Outbreak-Global Subscription E-Commerce market.  Additionally to compliment insights EXIM data, consumption, supply and demand Figures, raw price analysis, market revenue and gross margins.  Some of the companies listed in the research study are Flintobox, Hello Fresh, Edgewell Personal Care (Harry’s), Dollar Shave Club, Inc. , Netflix, PetSmart Inc, The Walt Disney Company Ltd. , Personalized Beauty Discovery, Inc (Ipsy), Blue Apron Holdings Inc.  & Nature Delivered Ltd etc.  Acquire Sample Report + All Related Tables & Graphs of COVID-19 Outbreak-Global Subscription E-Commerce Market Study Now @ :  If you are involved in the COVID-19 Outbreak- Subscription E-Commerce industry or intend to be, then this study will provide you complete viewpoint.  It’s vital you keep your market knowledge up to date segmented by Applications [Online & Offline], Product Types such as [, Beauty and Personal Care, Food and Beverage, Clothing and Fashion, Entertainment & Health and Fitness] and some major players in the industry.  COVID-19 Outbreak-Global Subscription E-Commerce Competitive Analysis: The key players are aiming innovation to increase efficiency and product life.  The long-term growth opportunities available in the sector is captured by ensuring constant process improvements and economic flexibility to spend in the optimal schemes.  Company profile section of players such as Flintobox, Hello Fresh, Edgewell Personal Care (Harry’s), Dollar Shave Club, Inc. , Netflix, PetSmart Inc, The Walt Disney Company Ltd. , Personalized Beauty Discovery, Inc (Ipsy), Blue Apron Holdings Inc.  & Nature Delivered Ltd etc.  includes its basic information like company legal name, website, headquarters, subsidiaries, its market position, history and 5 closest competitors by Market capitalization / revenue along with contact information.  Resource and Consumption – In extension with sales, this segment studies Resource and consumption for the COVID-19 Outbreak- Subscription E-Commerce Market.  Import export data is also provided by region if applicable.  Free Customization on the basis of client requirements on Immediate purchase: 1- Free country level breakdown any 5 countries of your interest.  2- Competitive breakdown of segment revenue by market players.  Enquire for customization in COVID-19 Outbreak-Global Subscription E-Commerce Market Report @  Important years taken into consideration in the study are as follows: Historical year – 2014-2019 Base year – 2019 Forecast period** – 2020 to 2026 [** unless otherwise stated] Focus on segments and sub-section of the Market are illuminated below: Geographical Analysis: North America (Covered in Chapter 7 and 14), United States, Canada, Mexico, Europe (Covered in Chapter 8 and 14), Germany, UK, France, Italy, Spain, Russia, Others, Asia-Pacific (Covered in Chapter 9 and 14), China, Japan, South Korea, Australia, India, Southeast Asia, Others, Middle East and Africa (Covered in Chapter 10 and 14), Saudi Arabia, UAE, Egypt, Nigeria, South Africa, Others, South America (Covered in Chapter 11 and 14), Brazil, Argentina, Columbia, Chile & Others,Rest of World etc On the Basis of Product Types of COVID-19 Outbreak- Subscription E-Commerce Market: , Beauty and Personal Care, Food and Beverage, Clothing and Fashion, Entertainment & Health and Fitness The Study Explores the Key Applications/End-Users of COVID-19 Outbreak- Subscription E-Commerce Market: Online & Offline Buy research study COVID-19 Outbreak- Subscription E-Commerce at Discounted Pricing @:  Most important Highlights of TOC: 1 Introduction of COVID-19 Outbreak- Subscription E-Commerce Market 1. 1 Overview of the Market 1. 2 Scope of Report 2 Exclusive Summary 3 Research Methodology 3. 1 Primary Interviews 3. 2 Data Mining 3. 3 Validation 3. 4 List of Statistics 4 COVID-19 Outbreak- Subscription E-Commerce Market Segment & Geographic Analysis [2014 -2026] 4. 1 By Type 4. 2 By Application 4. 3 By Region / Country 5 COVID-19 Outbreak- Subscription E-Commerce Market Outlook 5. 1 Overview 5. 2 Market Dynamics 5. 2. 1 Opportunities 5. 2. 2 Restraints 5. 2. 3 Drivers 5. 3 Five Force Model 5. 4 Value Chain Analysis 6 COVID-19 Outbreak- Subscription E-Commerce Market Competitive Landscape 6. 1 Overview 6. 2 Key Development Policies 6. 3 Company Market Standing Read Detailed Index of COVID-19 Outbreak- Subscription E-Commerce Market report @:  Thanks for reading this article; you can also get individual chapter wise section or region wise report version like LATAM, North America, Europe or Southeast Asia.  Media Contact Company Name: HTF Market Intelligence Consulting Private Limited Contact Person: Craig Francis Email: Send Email Phone: 2063171218 Address:Unit No.  429, Parsonage Road Ci', 'Subscription E-Commerce Market to Accelerate Growth with Netflix, Blue Apron, Hello Fresh']\n",
      "['Market Segment by Product Type Frequently Asked Questions What is the scope of the report? This market study covers the global and regional market with an in-depth analysis of the overall growth prospects in the market.  Furthermore, it sheds light on the comprehensive competitive landscape of the global market.  The report further offers a dashboard overview of leading companies encompassing their successful marketing strategies, market contribution, recent developments in both historic and present contexts.  What are the key segments in the market? By product type By End User/Applications By Technology By Region Which market dynamics affect the business? The report provides a detailed evaluation of the market by highlighting information on different aspects which include drivers, restraints, opportunities, and threats.  This information can help stakeholders to make appropriate decisions before investing.  The report forecast global Medical Radiation Detection, Monitoring & Safety market to grow to reach xx Million USD in 2021 with a CAGR of xx% during the period of 2021-2026. Projected and forecast revenue values are in constant U. S.  dollars, unadjusted for inflation.  Product values and regional markets are estimated by market analyst, data analyst and people from related industry, based on companys\\' revenue and applications market respectively. \"The report demonstrates detail coverage of Medical Radiation Detection, Monitoring & Safety industry and main market trends. The data sources include but not limited to reports of companys,international organizations and governments, Researcher\\'s surveys,and related industry news. The market research includes historical and forecast data from like demand, application details, price trends, and company shares of the leading Medical Radiation Detection, Monitoring & Safety by geography, especially focuses on the key regions like United States, European Union, China, and other regions. In addition, the report provides insight into main drivers,challenges,opportunities and risk of the market and strategies of suppliers.  Key players are profiled as well with their market shares in the global Medical Radiation Detection, Monitoring & Safety market discussed.  Overall, this report covers the historical situation, present status and the future prospects of the global Medical Radiation Detection, Monitoring & Safety market for 2016-2026. Moreover,the impact of COVID-19 is also concerned.  Since outbreak in December 2019, the COVID-19 virus has spread to over 100 countries and caused huge losses of lives and economy, and the global manufacturing, tourism and financial markets have been hit hard,while the online market increase.  Fortunately, with the development of vaccine and other effort by global governments and orgnizations, the nagetive impact of COVID-19 is excepted to subside and the global ecnomy is excepted to recover. Studying and analyzing the impact of Coronavirus COVID-19 on the Medical Radiation Detection, Monitoring & Safety industry, the report provide in-depth analysis and professtional advices on how to face the post COIVD-19 period. Gas-Filled DetectorsGeiger MullerSurvey MeterSolid-StateMarket Segment by Product ApplicationRadiologyDentalFirst AidNuclear MedicineOtherFinally, the report provides detailed profile and data information analysis of leading company. LandauerMirion TechnologiesIBA WorldwideThermo Fisher ScientificSun NuclearLudlum MeasurementsRadiation DetectionBiodex Medical SystemsArrow-TechFluke BiomedicalAmray MedicalInfabReport Includes:- xx data tables (appendix tables)- Overview of global Medical Radiation Detection, Monitoring & Safety market- An detailed key players analysis across regions- Analyses of global market trends, with historical data, estimates for 2021 and projections of compound annual growth rates (CAGRs) through 2026- Insights into regulatory and environmental developments- Information on the supply and demand scenario and evaluation of technological and investment opportunities in the Medical Radiation Detection, Monitoring & Safety market- Profiles of major players in the industry, including Landauer, Mirion Technologies, IBA Worldwide, Thermo Fisher Scientific, Sun Nuclear. . . . . Research Objectives1. To study and analyze the global Medical Radiation Detection, Monitoring & Safety consumption (value & volume) by key regions/countries, product type and application, history data from 2016 to 2020, and forecast to 2026. 2. To understand the structure of Medical Radiation Detection, Monitoring & Safety market by identifying its various subsegments. 3. Focuses on the key global Medical Radiation Detection, Monitoring & Safety manufacturers, to define, describe and analyze the sales volume, value, market share, market competition landscape, Porter\\'s five forces analysis, SWOT analysis and development plans in next few years. 4. To analyze the Medical Radiation Detection, Monitoring & Safety with respect to individual growth trends, future prospects, and their contribution to the total market. 5. To share detailed information about the key factors influencing the growth of the market (growth potential, opportunities, drivers, industry-specific challenges and risks). 6. To project the consumption of Medical Radiation Detection, Monitoring & Safety submarkets, with respect to key regions (along with their respective key countries). 7. To analyze competitive developments such as expansions, agreements, new product launches, and acquisitions in the market. 8. To strategically profile the key ', 'Global Medical Radiation Detection, Monitoring & Safety Market Research Report 2021, Forecast to 2026']\n",
      "['© Provided by The Indian Express Liquor prices in Punjab will remain unchanged in the next fiscal year even as the state has increased its quota for sale of liquor to enhance its revenue from excise.  Punjab Cabinet on Monday gave its nod to the Excise Policy 2021-22.  The state is looking at revenue collection of Rs 7,002 crore in the next fiscal against an expected collection of Rs 5,794 crore in the current fiscal.  This is Rs 300 crore more than the estimates in the budget 2020-21 at Rs 5,578 crore.  Finance Minister Manpreet Badal told the media that as per the realised collections of excise duty, the state had earned a revenue of Rs 5,027 crore in the last fiscal and this year the state had witnessed an increase of 15 per cent.  The state government was on the defensive in the current fiscal for hooch tragedy claiming over 100 lives.  The government had then launched an Operation Red Rose to nail the illegal sale of liquor.  “It is under this operation only that we have to increase the quota to be sold by the legal vends.  We will not allow the sale of illegal liquor.  Those buying from bootleggers will turn to the vends.  That is why we will allow the vends to sell more, with no change in prices of liquor so that the people do not have to shell out more,” A Venu Prasad, Additional Chief Secretary-cum-Financial Commissioner, Taxation, Punjab told The Indian Express.  He added that the quota of country made liquor (PML) is proposed to be raised by 12 per cent, that of Indian Made Foreign Liquor (IMFL) by 6 per cent and that of Beer by 4 per cent.  “This will not only help us check on bootleggers but also enhance our revenue collections by about 20 per cent,” added Prasad.  The government was also under attack this fiscal for not recording a rise in the excise collections.  Former Chief Secretary Karan Avtar Singh had come under attack from the ruling party leaders as well as the opposition for the curve of revenue from excise not registering growth.  RELIEF FOR MARRIAGE PALACES, HOTELS AND RESTAURANTS The annual fixed licence fee for bars in hotels and restaurants has been slashed by around 30 per cent, for marriage palaces by around 20 per cent and the fee on consumption of liquor (assessed fee) has also been reduced.  Manpreet Badal said the Cabinet allowed the slashing considering that Covid pandemic had hit the hospitality industry hard and the relief would help it recover.  The slashing was a demand of the hospitality industry.  The wholesale trade of liquor will be monitored online by the government replacing the present L-13 wholesale licensees.  A government statement after the Cabinet said that the state government is banking on the performance of the excise department during the year 2020-21 despite Covid-19 disruptions, which is now slated to garner around Rs 300 crores over and above the budgeted target of Rs 5,578 crores.  If successful, the government would be able to jump from Rs 5,073 crores in 2019-20 to Rs 7,000 crores in 2021-22, an increase of whopping 40 per cent in two years.  The department proposes to collect the additional revenue by increasing the quota.  In a first, the department has proposed to impose a quota for foreign liquor in Municipal Corporation areas and ‘A’ Class municipalities.  The excise policy has been formulated specially to give relief to those sections of the society which were affected negatively due to Covid-19.  The policy allows renewal of existing vends subject to lifting of additional liquor by the licensees.  It is likely to bring stability in the liquor trade and will also generate additional revenue for the state exchequer.  MORATORIUM ON NEW DISTILLERIES The state government has also decided to place a moratorium on setting up of new distilleries, breweries or bottling plants.  It has also decided no new Letter of Intent (LoIs) will be issued for establishing manufacturing units in the current year.  The government has also made it mandatory for the LoIs issued for setting up of a Bottling Plant to complete their project by March 31, 2023.  In order to maximise the revenue, a minimum guaranteed quota for imported foreign liquor has been introduced in Municipal Corporations, A-Class Municipal Committees etc.  The L-1 (Import)/L-1BB licensees will have to procure IFL from the custom bonded warehouses situated in Punjab only.  To encourage ethanol manufacturers and proper utilisation of agriculture produce, a new licence (E-2) has been introduced for setting up an ethanol based distillation plant with a nominal fee.  The border areas of the state of Punjab have been given relief by converting 25 per cent of the Fix', 'Excise Policy 2021-22: Liquor prices in Punjab unchanged, sale quota increased']\n",
      "[\"OPPO K7X launched with 5G support and quad-rear camera, this is the price Oppo K7x to the new 5G smartphone of the company or can also say that launches in China markets as the latest OPPO 5G smartphone Has been done. There was some information about this mobile phone last month but now it has been officially launched. In Oppo K7X you are also getting some special features, these features are also getting a quad-camera setup and octa-core processor. Apart from this, this mobile phone has been launched in Single RAM and Storage Model in addition to two different colors. Oppo K7X price and other details OPPO K7X has been launched in the same variant i.e. 6GB RAM and 128GB storage at the cost of CNY 1,499 i.e. approximately Rs 16,700 in the China market. This mobile phone has been launched in Black Mirror and Blue Shedo Color Option. Apart from this, it tells you that this mobile phone has also been brought to pre-order in China, as well as the phone's cell is going to start on November 11. Discuss now, there is no information about this that after all, when this mobile phone is going to bring for the cell in the market, or when it is going to happen. OPPO K7X Specifications and FEATURES OPPO K7X mobile phones have been launched on Color OS 7. 2 with Android 10, besides this mobile phone is getting a 6. 5-inch FHD + display. Apart from this, you are also getting protection of Corning Gorila Glass 3 on the screen. In this mobile phone i.e. you are getting the Octa-Core MediaTech Dimensity 720 processor in Oppo K7x, in addition to getting a 6GB LPDDR4X RAM. If we talk about photography etc, in this mobile phone i.e. you are getting a quad-camera setup in the Oppo K7X, besides you are getting a 48mp primary sensor, in addition to an 8MP ultra In addition to getting a 2MP black and white sensor in the phone, you are getting a 2MP macro lens in the phone. Apart from this, you can also see a 16MP Selfi camera, you can see it on the hole-punch cutout. In the mobile phone you are getting a non-expandable storage of 128GB, besides the phone you are getting 30W fast charging of a 5000mAh capacity. Although not only this mobile phone you dual bend or \", '5G fonts wave in the smartphone market, Oppo also launched the latest 5G phone. Digit hindi ']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea00efb10334315a916d4c0c4beb1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61462fc8927e49398628af2c70b26aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610e224e829b44e2b3e70479794d8523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(data_train)):\n",
    "        data_train[i][0]= preprocess_article(data_train[i][0].lstrip().rstrip().lower())\n",
    "        data_train[i][1]= preprocess_article(data_train[i][1].lstrip().rstrip().lower())\n",
    "for i in range(len(data_val)):\n",
    "        data_val[i][0]= preprocess_article(data_val[i][0].lstrip().rstrip().lower())\n",
    "        data_val[i][1]= preprocess_article(data_val[i][1].lstrip().rstrip().lower())\n",
    "\n",
    "#data_train=data[:3000]\n",
    "#data_val=data[3000:]\n",
    "\n",
    "\n",
    "model=T5ForConditionalGeneration.from_pretrained('t5-base').cuda()\n",
    "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
    "rouge1=Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge(sentence,ref):\n",
    "    s=''\n",
    "    flag=0\n",
    "    for char in sentence:\n",
    "        if char=='<':\n",
    "            flag=1\n",
    "        elif char=='>':\n",
    "            flag=0\n",
    "        elif flag==0:\n",
    "            s+=char\n",
    "\n",
    "    gen=re.sub('\\s+',' ',s).rstrip().lstrip()\n",
    "#     print(gen)\n",
    "    if gen=='':\n",
    "        return 0,0,0\n",
    "    rg=rouge1.get_scores(gen,ref)\n",
    "    r1,r2,rl=rg[0][\"rouge-1\"]['f'], \\\n",
    "    rg[0][\"rouge-2\"]['f'],rg[0][\"rouge-l\"]['f']\n",
    "    \n",
    "    return r1,r2,rl\n",
    "\n",
    "def generate_batch(data):\n",
    "    output=random.sample(data,4)\n",
    "\n",
    "    inp,label=[],[]\n",
    "    for dat in output:\n",
    "            inp.append(dat[0])\n",
    "            label.append(dat[1])\n",
    "            \n",
    "    return inp,label\n",
    "def val(dev_data):\n",
    "    with torch.no_grad():\n",
    "        r1_,r2_,rl_=0,0,0\n",
    "        candidate_corpus,references_corpus=[],[]\n",
    "\n",
    "        for line in dev_data:\n",
    "            inp,label=[line[0]],[line[1]]\n",
    "            input=tokenizer.prepare_seq2seq_batch(src_texts=inp,\n",
    "                                                  tgt_texts=label, padding=True, return_tensors='pt')\n",
    "\n",
    "            output=model.generate(input_ids=input['input_ids'].cuda(),\n",
    "                                  num_beams=5, early_stopping=True, max_length=20)\n",
    "            out=tokenizer.batch_decode(output)\n",
    "            torch.cuda.empty_cache()\n",
    "            out[0] = re.sub(r\"<\\S+\", \"\", out[0])\n",
    "            #print(label[0])\n",
    "            #print(out[0])\n",
    "            #print(\"--------------------------------------------------------------------------------------------------------------\")\n",
    "            candidate_corpus.append(tokenizer.tokenize(out[0]))\n",
    "            references_corpus.append([tokenizer.tokenize(label[0])])\n",
    "            \n",
    "            r1,r2,rl=rouge(out[0],line[1])\n",
    "            del output\n",
    "            del out\n",
    "            del input\n",
    "            del inp\n",
    "            del label\n",
    "            r1_+=r1\n",
    "            r2_+=r2\n",
    "            rl_+=rl\n",
    "\n",
    "        r1_/=(len(dev_data)*0.01)\n",
    "        r2_/=(len(dev_data)*0.01)\n",
    "        rl_/=(len(dev_data)*0.01)\n",
    "        bleu=0\n",
    "        bleu=100*bleu_score(candidate_corpus, references_corpus)\n",
    "\n",
    "        return r1_,r2_,rl_,bleu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=50, training loss=1.1582945156097413\n",
      "iteration=100, training loss=0.6915342581272125\n",
      "iteration=150, training loss=0.6186654216051102\n",
      "iteration=200, training loss=0.5549868321418763\n",
      "iteration=250, training loss=0.5175634422898292\n",
      "iteration=300, training loss=0.4748349702358246\n",
      "iteration=350, training loss=0.4163611927628517\n",
      "iteration=400, training loss=0.450492101162672\n",
      "iteration=450, training loss=0.44888476610183714\n",
      "iteration=500, training loss=0.4688331997394562\n",
      "iteration=550, training loss=0.4223625707626343\n",
      "iteration=600, training loss=0.4333072492480278\n",
      "iteration=650, training loss=0.4417973732948303\n",
      "iteration=700, training loss=0.4046163882315159\n",
      "iteration=750, training loss=0.37463323086500167\n",
      "iteration=800, training loss=0.3895107523351908\n",
      "iteration=850, training loss=0.3823143169283867\n",
      "iteration=900, training loss=0.36099899366497995\n",
      "iteration=950, training loss=0.37028553038835527\n",
      "iteration=1000, training loss=0.3615856957435608\n",
      "iteration=1050, training loss=0.33915165573358536\n",
      "iteration=1100, training loss=0.3482396093010902\n",
      "iteration=1150, training loss=0.3563213196396828\n",
      "iteration=1200, training loss=0.3545937448740005\n",
      "iteration=1250, training loss=0.3456981159746647\n",
      "iteration=1300, training loss=0.36216232404112814\n",
      "iteration=1350, training loss=0.33215843737125395\n",
      "iteration=1400, training loss=0.33121546685695646\n",
      "iteration=1450, training loss=0.3358986170589924\n",
      "iteration=1500, training loss=0.3320057176053524\n",
      "iteration=1550, training loss=0.3099973864853382\n",
      "iteration=1600, training loss=0.3052000579237938\n",
      "iteration=1650, training loss=0.30233222045004365\n",
      "iteration=1700, training loss=0.30910112962126735\n",
      "iteration=1750, training loss=0.29903473243117334\n",
      "iteration=1800, training loss=0.2930836844444275\n",
      "iteration=1850, training loss=0.3200657141208649\n",
      "iteration=1900, training loss=0.2897606112062931\n",
      "iteration=1950, training loss=0.27962222293019295\n",
      "iteration=2000, training loss=0.29220885276794434\n",
      "iteration=2050, training loss=0.2951661144196987\n",
      "iteration=2100, training loss=0.28767585441470145\n",
      "iteration=2150, training loss=0.29280088722705844\n",
      "iteration=2200, training loss=0.27143710941076277\n",
      "iteration=2250, training loss=0.2624128873646259\n",
      "iteration=2300, training loss=0.261361311674118\n",
      "iteration=2350, training loss=0.2774340792000294\n",
      "iteration=2400, training loss=0.24092060416936875\n",
      "iteration=2450, training loss=0.2463846293091774\n",
      "iteration=2500, training loss=0.23630477294325827\n",
      "iteration=2550, training loss=0.2724790469557047\n",
      "iteration=2600, training loss=0.2803243868052959\n",
      "iteration=2650, training loss=0.25466790556907654\n",
      "iteration=2700, training loss=0.2451281675696373\n",
      "iteration=2750, training loss=0.26401774093508723\n",
      "iteration=2800, training loss=0.24285577394068242\n",
      "iteration=2850, training loss=0.23525673680007458\n",
      "iteration=2900, training loss=0.2379891251027584\n",
      "iteration=2950, training loss=0.2572573705017567\n",
      "iteration=3000, training loss=0.22551445346325635\n",
      "validation BLEU=26.801269475487686, validation R1=37.255646305078116, validation R2=26.254302937239196, validation RL=36.21190837490639\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer=optim.AdamW(model.parameters(),lr=0.00001)\n",
    "\n",
    "scalar=0\n",
    "val_score=0\n",
    "for i in range(3000):\n",
    "        model.train()\n",
    "        inp,label=generate_batch(data_train)\n",
    "        input=tokenizer.prepare_seq2seq_batch(src_texts=inp, tgt_texts=label, padding=True, return_tensors='pt',max_length=600,truncation=True)\n",
    "        outputs=model(input_ids=input['input_ids'].cuda(),labels=input['labels'].cuda())\n",
    "        loss=outputs[0]\n",
    "        \n",
    "        scalar+=loss.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        del outputs\n",
    "        del input\n",
    "        del inp\n",
    "        del label\n",
    "        if(i+1)%50==0:\n",
    "                print('iteration={}, training loss={}'.format(i+1,scalar/(4*50)))\n",
    "                scalar=0\n",
    "        if(i+1)%3000==0:\n",
    "                r1,r2,rl,bleu=val(data_x)\n",
    "                print('validation BLEU={}, validation R1={}, validation R2={}, validation RL={}'.format(bleu,r1,r2,rl))\n",
    "                \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation BLEU=28.904716014317906, validation R1=39.72569546875942, validation R2=26.8504839602334, validation RL=38.68267632367739\n"
     ]
    }
   ],
   "source": [
    "r1,r2,rl,bleu=val(data_val)\n",
    "print('validation BLEU={}, validation R1={}, validation R2={}, validation RL={}'.format(bleu,r1,r2,rl))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'t5_mod.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(optimizer.state_dict(),'optt5_.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
