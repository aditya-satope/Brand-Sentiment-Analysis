{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mainClassifier-99%+.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7d6635eac944d0383f96f3ca04cc10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1fa4a915b0449f1b087020b6c2a2cc2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ed7717613644bddb163789b3c9183ab",
              "IPY_MODEL_cb89dd697aa7431c9448aef32d3348c5"
            ]
          }
        },
        "d1fa4a915b0449f1b087020b6c2a2cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ed7717613644bddb163789b3c9183ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b03381df4ec54955b0d79082437c0af3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddef48ade79d4a6a8f86d0cb2d3324b4"
          }
        },
        "cb89dd697aa7431c9448aef32d3348c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c7a504c1e2e48e7906bc5833d2db826",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 599kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9764c0f32444932808bcd81d2117416"
          }
        },
        "b03381df4ec54955b0d79082437c0af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddef48ade79d4a6a8f86d0cb2d3324b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c7a504c1e2e48e7906bc5833d2db826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9764c0f32444932808bcd81d2117416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4648241b28b341b3b5784028670287a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_533ca459f6054c5fbf277cf61dad78fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ba278cd112b4dbcb83f0efd506afa67",
              "IPY_MODEL_7e0635670dd4404dbba38ce7f837d63d"
            ]
          }
        },
        "533ca459f6054c5fbf277cf61dad78fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ba278cd112b4dbcb83f0efd506afa67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c141803a457943bdb8e9ee1a00a3011b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_657bd4966bc641ab823d00ae83cc5181"
          }
        },
        "7e0635670dd4404dbba38ce7f837d63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e39a20f02c524c3d8fb41bf526bfef14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.13kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2465ca94c47248b3ab81e0ff387c19e9"
          }
        },
        "c141803a457943bdb8e9ee1a00a3011b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "657bd4966bc641ab823d00ae83cc5181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e39a20f02c524c3d8fb41bf526bfef14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2465ca94c47248b3ab81e0ff387c19e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2399a12d9ca847da9cd1f7372811a6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_024c039b16784aa680bbf32409d1ba1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d2bcd569f224893a87e4d5fdb0ed1be",
              "IPY_MODEL_349e225e2a334a78a06aa1d1451b4edb"
            ]
          }
        },
        "024c039b16784aa680bbf32409d1ba1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d2bcd569f224893a87e4d5fdb0ed1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fdc62cf7cf13411184e320a61d675116",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d04135e807f471cae13034e2ef27c0b"
          }
        },
        "349e225e2a334a78a06aa1d1451b4edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3eae617bfc949f08e35ea95fd16e277",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:46&lt;00:00, 9.44MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7bd06bc8cca47b8a9a062908185de78"
          }
        },
        "fdc62cf7cf13411184e320a61d675116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d04135e807f471cae13034e2ef27c0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3eae617bfc949f08e35ea95fd16e277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7bd06bc8cca47b8a9a062908185de78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4g0nqzS4rDi",
        "outputId": "86f19379-17b5-4bea-feef-b3f21dfed99d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Vy8RKJ42NO"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLM_11nSRxpj"
      },
      "source": [
        "#### Train DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIqgMa-mmI1g"
      },
      "source": [
        "tweetPath = '/content/drive/MyDrive/interIIT/tweet_train_cleaned.pkl'\r\n",
        "articlePath = '/content/drive/MyDrive/interIIT/article_train_cleaned.pkl'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "_iUsItMK5XS5",
        "outputId": "0054f2c6-707d-4106-da49-882cdb6cc2be"
      },
      "source": [
        "tweets = pd.read_pickle(tweetPath)\r\n",
        "tweets.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mobile_Tech_Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3095.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.250081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.433129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Mobile_Tech_Tag\n",
              "count      3095.000000\n",
              "mean          0.250081\n",
              "std           0.433129\n",
              "min           0.000000\n",
              "25%           0.000000\n",
              "50%           0.000000\n",
              "75%           0.500000\n",
              "max           1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "7bbwH4yhml4u",
        "outputId": "013281b2-69a7-4ff8-bfda-598754f50dc9"
      },
      "source": [
        "articles = pd.read_pickle(articlePath)\r\n",
        "articles.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3095.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.243619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.429335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Mobile_Tech_Flag\n",
              "count       3095.000000\n",
              "mean           0.243619\n",
              "std            0.429335\n",
              "min            0.000000\n",
              "25%            0.000000\n",
              "50%            0.000000\n",
              "75%            0.000000\n",
              "max            1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNvcbrA_oqDs",
        "outputId": "27f50006-008d-491e-cc77-81abdb417b24"
      },
      "source": [
        "articles['Mobile_Tech_Flag'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2341\n",
              "1     754\n",
              "Name: Mobile_Tech_Flag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkuirqVSnot_"
      },
      "source": [
        "newData = articles.drop(['Headline','urls'],axis=1)\r\n",
        "newtweet = pd.DataFrame({\r\n",
        "    'Text_ID': tweets['Tweet_ID'],\r\n",
        "    'Text': tweets['Tweet'],\r\n",
        "    'Mobile_Tech_Flag': tweets['Mobile_Tech_Tag']\r\n",
        "})\r\n",
        "newData = newData.append(newtweet)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CirgdtJzQ_M_"
      },
      "source": [
        "newData.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSbU7bPtR4Tl"
      },
      "source": [
        "### Val DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3i7ZsulR3xN"
      },
      "source": [
        "tweetvPath = '/content/drive/MyDrive/interIIT/tweet_dev_cleaned.pkl'\r\n",
        "artvPath = '/content/drive/MyDrive/interIIT/article_dev_cleaned.pkl'\r\n",
        "vtweets = pd.read_pickle(tweetvPath)\r\n",
        "varticle = pd.read_pickle(artvPath)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tR2BtsbSmKz"
      },
      "source": [
        "# vnewData = varticle.drop(['Headline','urls'],axis=1)\r\n",
        "vnewtweet = pd.DataFrame({\r\n",
        "    'Text_ID': vtweets['Tweet_ID'],\r\n",
        "    'Text': vtweets['Tweet'],\r\n",
        "    'Mobile_Tech_Flag': vtweets['Mobile_Tech_Tag']\r\n",
        "})\r\n",
        "# vnewData = vnewData.append(vnewtweet)\r\n",
        "# vnewData.reset_index(drop=True,inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "4yx0gSru6r6u",
        "outputId": "6eeb76de-70bc-4523-95aa-fba0d93a26e9"
      },
      "source": [
        "vnewtweet"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet_2285</td>\n",
              "      <td>Jaise Apka Dimag Twitter Pe Baith ke Hugg Skte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet_0934</td>\n",
              "      <td>No one thought to make restaurant workers elig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet_3991</td>\n",
              "      <td>चीनी मोबाइल कंपनी रियलमी ने अपना Realme V15 5G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tweet_0267</td>\n",
              "      <td>Barnsley have signed Orlando City striker Dary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tweet_2619</td>\n",
              "      <td>Intezaar intezaar ka shor hay kone kone mei Ku...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>tweet_3485</td>\n",
              "      <td>We are the pioneers of ____ Smartphone Camera ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>tweet_0549</td>\n",
              "      <td>QT  ; An outbreak of the #Nipah virus in China...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>tweet_1702</td>\n",
              "      <td>Loan de k wapis nahi kr rhi thi than  ne mere ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>tweet_0251</td>\n",
              "      <td>An outbreak of the Nipah virus in China, with ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>tweet_1858</td>\n",
              "      <td>आपका बैंक अब आपके दरवाजे पर। Doorstep banking ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>505 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Text_ID  ... Mobile_Tech_Flag\n",
              "0    tweet_2285  ...                0\n",
              "1    tweet_0934  ...                0\n",
              "2    tweet_3991  ...                1\n",
              "3    tweet_0267  ...                0\n",
              "4    tweet_2619  ...                0\n",
              "..          ...  ...              ...\n",
              "500  tweet_3485  ...                1\n",
              "501  tweet_0549  ...                0\n",
              "502  tweet_1702  ...                0\n",
              "503  tweet_0251  ...                0\n",
              "504  tweet_1858  ...                0\n",
              "\n",
              "[505 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1mI6jVGXpU4"
      },
      "source": [
        "X_train = newData.Text.values\r\n",
        "y_train = newData.Mobile_Tech_Flag.values\r\n",
        "X_val = vnewtweet.Text.values\r\n",
        "y_val = vnewtweet.Mobile_Tech_Flag.values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qjWEZ9oX9qM",
        "outputId": "d0d672f6-a1bd-48c6-d9b6-9726657c85fe"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpnchv4yXoqz",
        "outputId": "2059f112-2c21-489d-e65c-06ae1c12aa36"
      },
      "source": [
        "import torch\r\n",
        "\r\n",
        "if torch.cuda.is_available():       \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\r\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAq6jA75aDgN",
        "outputId": "1ce540da-268a-4839-e11c-e63cc1f8ecc2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 10 11:41:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    30W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_nZzd--YrGQ",
        "outputId": "44834220-442d-4b6b-86b2-1d2c46e553b1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=75e2410a785d90909da0f813c6f96c6293813ef48623567b7cac086d851e201c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gJ_islGWwax",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c7d6635eac944d0383f96f3ca04cc10d",
            "d1fa4a915b0449f1b087020b6c2a2cc2",
            "5ed7717613644bddb163789b3c9183ab",
            "cb89dd697aa7431c9448aef32d3348c5",
            "b03381df4ec54955b0d79082437c0af3",
            "ddef48ade79d4a6a8f86d0cb2d3324b4",
            "1c7a504c1e2e48e7906bc5833d2db826",
            "b9764c0f32444932808bcd81d2117416"
          ]
        },
        "outputId": "5f024075-bb52-49a0-9605-63b102cbe8fb"
      },
      "source": [
        "from transformers import BertTokenizer\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\r\n",
        "def preprocessing_for_bert(data):\r\n",
        "    input_ids = []\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    # For every sentence...\r\n",
        "    for sent in data:\r\n",
        "        encoded_sent = tokenizer.encode_plus(\r\n",
        "            text=sent,  \r\n",
        "            add_special_tokens=True,        \r\n",
        "            max_length=MAX_LEN,             \r\n",
        "            pad_to_max_length=True,         \r\n",
        "            #return_tensors='pt',           \r\n",
        "            return_attention_mask=True   \r\n",
        "            )\r\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\r\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\r\n",
        "\r\n",
        "    # Convert lists to tensors\r\n",
        "    input_ids = torch.tensor(input_ids)\r\n",
        "    attention_masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7d6635eac944d0383f96f3ca04cc10d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACpQkcaYZvyx",
        "outputId": "7489a596-db42-4544-b3c4-2cc8939647ca"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJGxV4hnZBm0"
      },
      "source": [
        "# all_tweets = newData.Text.values\r\n",
        "\r\n",
        "# # Encode our concatenated data\r\n",
        "# encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\r\n",
        "\r\n",
        "# # Find the maximum length\r\n",
        "# max_len = max([len(sent) for sent in encoded_tweets])\r\n",
        "# print('Max length: ', max_len)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "9ukaWXe7Tb0c",
        "outputId": "363891fc-d08d-4815-b105-17ec973c8f25"
      },
      "source": [
        "X = X_train[4]\r\n",
        "X"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Oppo K7x को 5G सपोर्ट और क्वाड-रियर कैमरा के साथ किया गया लॉन्च, ये है कीमत Oppo K7x को कंपनी की ओर से ओप्पो के नए 5G स्मार्टफ़ोन या ऐसा भी कह सकते हैं कि लेटेस्ट Oppo 5G स्मार्टफ़ोन के तौर पर चीन के बाजारों में लॉन्च कर दिया गया है। इस मोबाइल फोन के बारे में पिछले महीने कुछ जानकारी सामने आई थी लेकिन अब इसे आधिकारिक तौर पर लॉन्च कर दिया गया है। Oppo K7x में आपको कुछ खास फीचर्स भी मिल रहे है, इन फीचर्स में एक क्वाड-कैमरा सेटअप और ओक्टा-कोर प्रोसेसर भी मिल रहा है। इसके अलावा इस मोबाइल फोन दो अलग अलग रंगों के अलावा सिंगल रैम और स्टोरेज मॉडल में लॉन्च किया गया है। Oppo K7x की कीमत और अन्य डिटेल्स Oppo K7x को चीन के बाजार में CNY 1,499 यानी लगभग Rs 16,700 की कीमत में एक ही वैरिएंट यानी 6GB रैम और 128GB स्टोरेज में लॉन्च कर दिया गया है। इस मोबाइल फोन को ब्लैक मिरर और ब्लू शैडो कलर ऑप्शन में लॉन्च किया गया है। इसके अलावा आपको बता देते है कि इस मोबाइल फोन को चीन में प्री-ऑर्डर के लिए भी लाया जा चुका है, साथ ही बता देते है कि फोन की सेल 11 नवम्बर को शुरू हो जाने वाली है। अभी की चर्चा करें तो इस बारे में कोई भी जानकारी मौजूद नहीं है कि आखिर इस मोबाइल फोन को भारत के बाजार में सेल के लिए कब लाया जाने वाला है, या इसकी सेल कब होने वाली है। Oppo K7x स्पेसिफ़िकेशन्स और फीचर्स Oppo K7x मोबाइल फोन को एंड्राइड 10 के साथ कलरOS 7. 2 पर लॉन्च किया गया है, इसके अलावा इस मोबाइल फोन में आपको एक 6. 5-इंच की FHD+ डिस्प्ले मिल रही है। इसके अलावा स्क्रीन पर आपको कोर्निंग गोरिला ग्लास 3 का प्रोटेक्शन भी मिल रहा है। इस मोबाइल फोन में यानी Oppo K7x में आपको ओक्टा-कोर मीडियाटेक Dimensity 720 प्रोसेसर मिल रहा है, इसके अलावा फोन में आपको एक 6GB की LPDDR4x रैम मिल रही है। अगर हम फोटोग्राफी आदि की बात करते हैं तो इस मोबाइल फोन में यानी Oppo K7x में आपको एक क्वाड-कैमरा सेटअप मिल रहा है, इसके अलावा फोन में आपको एक 48MP का प्राइमरी सेंसर मिल रहा है, इसके अलावा फोन में आपको एक 8MP का अल्ट्रा-वाइड-एंगल कैमरा मिल रहा है, इसके अलावा फोन में आपको एक 2MP का ब्लैक और वाइट सेंसर मिल रहा है, इसके अलावा फोन में आपको एक 2MP का मैक्रो लेंस भी मिल रहा है। इसके अलावा फोन में आपको एक 16MP का सेल्फी कैमरा भी मिल रहा है, इसे आप होल-पंच कटआउट पर देख सकते हैं। मोबाइल फोन में आपको 128GB की नॉन-एक्सपेंडेबल स्टोरेज मिल रही है, इसके अलावा फोन में आपको एक 5000mAh क्षमता की 30W की फ़ास्ट चार्जिंग मिल रही है। हालाँकि इतना ही नहीं इस मोबाइल फोन में आपको ड्यूल बेंड वा'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDLnllBsVKVj",
        "outputId": "69fdf7ad-94c5-4efb-9f4d-70e582218c69"
      },
      "source": [
        "MAX_LEN = 300\r\n",
        "\r\n",
        "token_ids = list(preprocessing_for_bert([X])[0].squeeze().numpy())\r\n",
        "print('Original: ', X)\r\n",
        "print('Token IDs: ', token_ids)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Oppo K7x को 5G सपोर्ट और क्वाड-रियर कैमरा के साथ किया गया लॉन्च, ये है कीमत Oppo K7x को कंपनी की ओर से ओप्पो के नए 5G स्मार्टफ़ोन या ऐसा भी कह सकते हैं कि लेटेस्ट Oppo 5G स्मार्टफ़ोन के तौर पर चीन के बाजारों में लॉन्च कर दिया गया है। इस मोबाइल फोन के बारे में पिछले महीने कुछ जानकारी सामने आई थी लेकिन अब इसे आधिकारिक तौर पर लॉन्च कर दिया गया है। Oppo K7x में आपको कुछ खास फीचर्स भी मिल रहे है, इन फीचर्स में एक क्वाड-कैमरा सेटअप और ओक्टा-कोर प्रोसेसर भी मिल रहा है। इसके अलावा इस मोबाइल फोन दो अलग अलग रंगों के अलावा सिंगल रैम और स्टोरेज मॉडल में लॉन्च किया गया है। Oppo K7x की कीमत और अन्य डिटेल्स Oppo K7x को चीन के बाजार में CNY 1,499 यानी लगभग Rs 16,700 की कीमत में एक ही वैरिएंट यानी 6GB रैम और 128GB स्टोरेज में लॉन्च कर दिया गया है। इस मोबाइल फोन को ब्लैक मिरर और ब्लू शैडो कलर ऑप्शन में लॉन्च किया गया है। इसके अलावा आपको बता देते है कि इस मोबाइल फोन को चीन में प्री-ऑर्डर के लिए भी लाया जा चुका है, साथ ही बता देते है कि फोन की सेल 11 नवम्बर को शुरू हो जाने वाली है। अभी की चर्चा करें तो इस बारे में कोई भी जानकारी मौजूद नहीं है कि आखिर इस मोबाइल फोन को भारत के बाजार में सेल के लिए कब लाया जाने वाला है, या इसकी सेल कब होने वाली है। Oppo K7x स्पेसिफ़िकेशन्स और फीचर्स Oppo K7x मोबाइल फोन को एंड्राइड 10 के साथ कलरOS 7. 2 पर लॉन्च किया गया है, इसके अलावा इस मोबाइल फोन में आपको एक 6. 5-इंच की FHD+ डिस्प्ले मिल रही है। इसके अलावा स्क्रीन पर आपको कोर्निंग गोरिला ग्लास 3 का प्रोटेक्शन भी मिल रहा है। इस मोबाइल फोन में यानी Oppo K7x में आपको ओक्टा-कोर मीडियाटेक Dimensity 720 प्रोसेसर मिल रहा है, इसके अलावा फोन में आपको एक 6GB की LPDDR4x रैम मिल रही है। अगर हम फोटोग्राफी आदि की बात करते हैं तो इस मोबाइल फोन में यानी Oppo K7x में आपको एक क्वाड-कैमरा सेटअप मिल रहा है, इसके अलावा फोन में आपको एक 48MP का प्राइमरी सेंसर मिल रहा है, इसके अलावा फोन में आपको एक 8MP का अल्ट्रा-वाइड-एंगल कैमरा मिल रहा है, इसके अलावा फोन में आपको एक 2MP का ब्लैक और वाइट सेंसर मिल रहा है, इसके अलावा फोन में आपको एक 2MP का मैक्रो लेंस भी मिल रहा है। इसके अलावा फोन में आपको एक 16MP का सेल्फी कैमरा भी मिल रहा है, इसे आप होल-पंच कटआउट पर देख सकते हैं। मोबाइल फोन में आपको 128GB की नॉन-एक्सपेंडेबल स्टोरेज मिल रही है, इसके अलावा फोन में आपको एक 5000mAh क्षमता की 30W की फ़ास्ट चार्जिंग मिल रही है। हालाँकि इतना ही नहीं इस मोबाइल फोन में आपको ड्यूल बेंड वा\n",
            "Token IDs:  [101, 6728, 6873, 1047, 2581, 2595, 1315, 29879, 1019, 2290, 1338, 29864, 29879, 29869, 29856, 100, 1315, 29871, 29876, 29857, 1011, 1333, 29877, 29868, 29869, 1315, 29867, 29869, 29876, 1315, 1338, 29876, 29860, 1315, 29877, 29868, 29876, 1317, 29868, 29876, 100, 1010, 1332, 1339, 1315, 29878, 29867, 29859, 6728, 6873, 1047, 2581, 2595, 1315, 29879, 1315, 29864, 29863, 29878, 1315, 29878, 100, 1338, 100, 1315, 1327, 29850, 1019, 2290, 100, 1332, 29876, 100, 1330, 29878, 1315, 29875, 1338, 29851, 29859, 1339, 1315, 29877, 1334, 29856, 29874, 29856, 6728, 6873, 1019, 2290, 100, 1315, 100, 1328, 29869, 1318, 29878, 29863, 1315, 1329, 29876, 29855, 29876, 29869, 29879, 1331, 100, 1315, 29869, 1325, 29877, 29868, 29876, 1317, 29868, 29876, 1339, 1344, 100, 100, 100, 1315, 1329, 29876, 29869, 1331, 100, 1331, 29875, 29878, 29863, 100, 1319, 29876, 29863, 29851, 29876, 29869, 29878, 1338, 29876, 29867, 29863, 100, 1324, 29878, 1334, 29851, 29877, 29863, 1311, 29865, 100, 1312, 29862, 29877, 29851, 29876, 29869, 29877, 29851, 100, 1328, 29869, 100, 1315, 29869, 1325, 29877, 29868, 29876, 1317, 29868, 29876, 1339, 1344, 6728, 6873, 1047, 2581, 2595, 1331, 1312, 29864, 29851, 29879, 100, 1316, 29876, 29874, 100, 1330, 29878, 1331, 29877, 29870, 1333, 29875, 1339, 1010, 100, 100, 1331, 1314, 29851, 1315, 29871, 29876, 29857, 1011, 1315, 29867, 29869, 29876, 1338, 29856, 29847, 29864, 100, 100, 1011, 1315, 29879, 29869, 1328, 29869, 29879, 29874, 29874, 29869, 1330, 29878, 1331, 29877, 29870, 1333, 29875, 29876, 1339, 1344, 100, 1311, 29870, 29876, 29871, 29876, 100, 100, 100, 1325, 29879, 1311, 29870, 29853, 1311, 29870, 29853, 1333, 29853, 29879, 1315, 1311, 29870, 29876, 29871, 29876, 1338, 29877, 29853, 29870, 1333, 29867, 100, 1338, 29856, 29879, 29869, 29855, 100, 1331, 100, 1315, 29877, 29868, 29876, 1317, 29868, 29876, 1339, 1344, 6728, 6873, 1047, 2581, 2595, 1315, 29878, 1315, 102]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGROYPj4Z4lA",
        "outputId": "8777ce37-e766-4369-b807-da93f9782197"
      },
      "source": [
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\r\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3IxD7lqU8w6",
        "outputId": "070e9789-6fd3-49eb-f65b-3b6e5bff0f60"
      },
      "source": [
        "train_inputs.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6190, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dF2zKrzaQJN"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "train_labels = torch.tensor(y_train)\r\n",
        "val_labels = torch.tensor(y_val)\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Create the DataLoader for our training set\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "# Create the DataLoader for our validation set\r\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\r\n",
        "val_sampler = SequentialSampler(val_data)\r\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHyIJo6Zau-j",
        "outputId": "4630b1eb-83dc-4680-e154-a26c8ad28958"
      },
      "source": [
        "%time\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from transformers import BertModel\r\n",
        "\r\n",
        "# Create the BertClassfier class\r\n",
        "class BertClassifier(nn.Module):\r\n",
        "    def __init__(self, freeze_bert=False):\r\n",
        "        super(BertClassifier, self).__init__()\r\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\r\n",
        "        D_in, H, D_out = 768, 80, 2\r\n",
        "\r\n",
        "        # Instantiate BERT model\r\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\r\n",
        "\r\n",
        "        # Instantiate an one-layer feed-forward classifier\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Linear(D_in, H),\r\n",
        "            nn.ReLU(),\r\n",
        "            #nn.Dropout(0.5),\r\n",
        "            nn.Linear(H, D_out)\r\n",
        "        )\r\n",
        "\r\n",
        "        # Freeze the BERT model\r\n",
        "        if freeze_bert:\r\n",
        "            for param in self.bert.parameters():\r\n",
        "                param.requires_grad = False\r\n",
        "        \r\n",
        "    def forward(self, input_ids, attention_mask):\r\n",
        "        # Feed input to BERT\r\n",
        "        outputs = self.bert(input_ids=input_ids,\r\n",
        "                            attention_mask=attention_mask)\r\n",
        "        \r\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\r\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\r\n",
        "\r\n",
        "        # Feed input to classifier to compute logits\r\n",
        "        logits = self.classifier(last_hidden_state_cls)\r\n",
        "\r\n",
        "        return logits"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezOdylqTbG0b"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "def initialize_model(epochs=4):\r\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\r\n",
        "    \"\"\"\r\n",
        "    # Instantiate Bert Classifier\r\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\r\n",
        "\r\n",
        "    # Tell PyTorch to run the model on GPU\r\n",
        "    bert_classifier.to(device)\r\n",
        "\r\n",
        "    # Create the optimizer\r\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\r\n",
        "                      lr=1e-4,    # Default learning rate\r\n",
        "                      eps=1e-8    # Default epsilon value\r\n",
        "                      )\r\n",
        "\r\n",
        "    # Total number of training steps\r\n",
        "    total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "    # Set up the learning rate scheduler\r\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\r\n",
        "                                                num_warmup_steps=0, # Default value\r\n",
        "                                                num_training_steps=total_steps)\r\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66HfUiwbMXo"
      },
      "source": [
        "import random\r\n",
        "import time\r\n",
        "\r\n",
        "# Specify loss function\r\n",
        "loss_fn = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "def set_seed(seed_value=42):\r\n",
        "    \"\"\"Set seed for reproducibility.\r\n",
        "    \"\"\"\r\n",
        "    random.seed(seed_value)\r\n",
        "    np.random.seed(seed_value)\r\n",
        "    torch.manual_seed(seed_value)\r\n",
        "    torch.cuda.manual_seed_all(seed_value)\r\n",
        "\r\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\r\n",
        "    \"\"\"Train the BertClassifier model.\r\n",
        "    \"\"\"\r\n",
        "    # Start training loop\r\n",
        "    print(\"Start training...\\n\")\r\n",
        "    for epoch_i in range(epochs):\r\n",
        "        # =======================================\r\n",
        "        #               Training\r\n",
        "        # =======================================\r\n",
        "        # Print the header of the result table\r\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\r\n",
        "        print(\"-\"*70)\r\n",
        "\r\n",
        "        # Measure the elapsed time of each epoch\r\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\r\n",
        "\r\n",
        "        # Reset tracking variables at the beginning of each epoch\r\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\r\n",
        "\r\n",
        "        # Put the model into the training mode\r\n",
        "        model.train()\r\n",
        "\r\n",
        "        # For each batch of training data...\r\n",
        "        for step, batch in enumerate(train_dataloader):\r\n",
        "            batch_counts +=1\r\n",
        "            # Load batch to GPU\r\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\r\n",
        "\r\n",
        "            # Zero out any previously calculated gradients\r\n",
        "            model.zero_grad()\r\n",
        "\r\n",
        "            # Perform a forward pass. This will return logits.\r\n",
        "            logits = model(b_input_ids, b_attn_mask)\r\n",
        "\r\n",
        "            # Compute loss and accumulate the loss values\r\n",
        "            loss = loss_fn(logits, b_labels)\r\n",
        "            batch_loss += loss.item()\r\n",
        "            total_loss += loss.item()\r\n",
        "\r\n",
        "            # Perform a backward pass to calculate gradients\r\n",
        "            loss.backward()\r\n",
        "\r\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\r\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "            # Update parameters and the learning rate\r\n",
        "            optimizer.step()\r\n",
        "            scheduler.step()\r\n",
        "\r\n",
        "            # Print the loss values and time elapsed for every 20 batches\r\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\r\n",
        "                # Calculate time elapsed for 20 batches\r\n",
        "                time_elapsed = time.time() - t0_batch\r\n",
        "\r\n",
        "                # Print training results\r\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\r\n",
        "\r\n",
        "                # Reset batch tracking variables\r\n",
        "                batch_loss, batch_counts = 0, 0\r\n",
        "                t0_batch = time.time()\r\n",
        "\r\n",
        "        # Calculate the average loss over the entire training data\r\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\r\n",
        "\r\n",
        "        print(\"-\"*70)\r\n",
        "        # =======================================\r\n",
        "        #               Evaluation\r\n",
        "        # =======================================\r\n",
        "        if evaluation == True:\r\n",
        "            # After the completion of each training epoch, measure the model's performance\r\n",
        "            # on our validation set.\r\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\r\n",
        "\r\n",
        "            # Print performance over the entire training data\r\n",
        "            time_elapsed = time.time() - t0_epoch\r\n",
        "            \r\n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\r\n",
        "            print(\"-\"*70)\r\n",
        "        print(\"\\n\")\r\n",
        "    \r\n",
        "    print(\"Training complete!\")\r\n",
        "\r\n",
        "\r\n",
        "def evaluate(model, val_dataloader):\r\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\r\n",
        "    on our validation set.\r\n",
        "    \"\"\"\r\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\r\n",
        "    # the test time.\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # Tracking variables\r\n",
        "    val_accuracy = []\r\n",
        "    val_loss = []\r\n",
        "\r\n",
        "    # For each batch in our validation set...\r\n",
        "    for batch in val_dataloader:\r\n",
        "        # Load batch to GPU\r\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\r\n",
        "\r\n",
        "        # Compute logits\r\n",
        "        with torch.no_grad():\r\n",
        "            logits = model(b_input_ids, b_attn_mask)\r\n",
        "\r\n",
        "        # Compute loss\r\n",
        "        loss = loss_fn(logits, b_labels)\r\n",
        "        val_loss.append(loss.item())\r\n",
        "\r\n",
        "        # Get the predictions\r\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\r\n",
        "\r\n",
        "        # Calculate the accuracy rate\r\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\r\n",
        "        val_accuracy.append(accuracy)\r\n",
        "\r\n",
        "    # Compute the average accuracy and loss over the validation set.\r\n",
        "    val_loss = np.mean(val_loss)\r\n",
        "    val_accuracy = np.mean(val_accuracy)\r\n",
        "\r\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736,
          "referenced_widgets": [
            "4648241b28b341b3b5784028670287a9",
            "533ca459f6054c5fbf277cf61dad78fe",
            "2ba278cd112b4dbcb83f0efd506afa67",
            "7e0635670dd4404dbba38ce7f837d63d",
            "c141803a457943bdb8e9ee1a00a3011b",
            "657bd4966bc641ab823d00ae83cc5181",
            "e39a20f02c524c3d8fb41bf526bfef14",
            "2465ca94c47248b3ab81e0ff387c19e9",
            "2399a12d9ca847da9cd1f7372811a6e7",
            "024c039b16784aa680bbf32409d1ba1b",
            "6d2bcd569f224893a87e4d5fdb0ed1be",
            "349e225e2a334a78a06aa1d1451b4edb",
            "fdc62cf7cf13411184e320a61d675116",
            "2d04135e807f471cae13034e2ef27c0b",
            "a3eae617bfc949f08e35ea95fd16e277",
            "d7bd06bc8cca47b8a9a062908185de78"
          ]
        },
        "id": "A4gJSkARbYmg",
        "outputId": "59481c9c-5422-42d8-c7d5-5d960038f1f1"
      },
      "source": [
        "set_seed(42)   \r\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\r\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4648241b28b341b3b5784028670287a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2399a12d9ca847da9cd1f7372811a6e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.339676   |     -      |     -     |   20.33  \n",
            "   1    |   40    |   0.185707   |     -      |     -     |   18.99  \n",
            "   1    |   60    |   0.135050   |     -      |     -     |   19.06  \n",
            "   1    |   80    |   0.138278   |     -      |     -     |   19.08  \n",
            "   1    |   100   |   0.083728   |     -      |     -     |   19.01  \n",
            "   1    |   120   |   0.113012   |     -      |     -     |   19.00  \n",
            "   1    |   140   |   0.118085   |     -      |     -     |   18.99  \n",
            "   1    |   160   |   0.132993   |     -      |     -     |   19.02  \n",
            "   1    |   180   |   0.104871   |     -      |     -     |   18.98  \n",
            "   1    |   193   |   0.073342   |     -      |     -     |   11.86  \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.145985   |  0.011582  |   99.61   |  189.30  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.061292   |     -      |     -     |   19.98  \n",
            "   2    |   40    |   0.052388   |     -      |     -     |   18.96  \n",
            "   2    |   60    |   0.076184   |     -      |     -     |   19.00  \n",
            "   2    |   80    |   0.026833   |     -      |     -     |   18.97  \n",
            "   2    |   100   |   0.071336   |     -      |     -     |   18.97  \n",
            "   2    |   120   |   0.080650   |     -      |     -     |   18.98  \n",
            "   2    |   140   |   0.044302   |     -      |     -     |   19.06  \n",
            "   2    |   160   |   0.029422   |     -      |     -     |   19.04  \n",
            "   2    |   180   |   0.058249   |     -      |     -     |   19.00  \n",
            "   2    |   193   |   0.070792   |     -      |     -     |   11.82  \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.056674   |  0.023074  |   99.61   |  188.74  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRii7CVbc4O"
      },
      "source": [
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "def bert_predict(model, test_dataloader):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    all_logits = []\r\n",
        "    for batch in test_dataloader:\r\n",
        "        # Load batch to GPU\r\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\r\n",
        "\r\n",
        "        # Compute logits\r\n",
        "        with torch.no_grad():\r\n",
        "            logits = model(b_input_ids, b_attn_mask)\r\n",
        "        all_logits.append(logits)\r\n",
        "    \r\n",
        "    # Concatenate logits from each batch\r\n",
        "    all_logits = torch.cat(all_logits, dim=0)\r\n",
        "\r\n",
        "    # Apply softmax to calculate probabilities\r\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\r\n",
        "\r\n",
        "    return probs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJuifmc5jUIG"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\r\n",
        "def evaluate_roc(probs, y_true):\r\n",
        "    preds = probs[:, 1]\r\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\r\n",
        "    roc_auc = auc(fpr, tpr)\r\n",
        "    print(f'AUC: {roc_auc:.4f}')\r\n",
        "       \r\n",
        "    # Get accuracy over the test set\r\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\r\n",
        "    accuracy = accuracy_score(y_true, y_pred)\r\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\r\n",
        "    \r\n",
        "    # Plot ROC AUC\r\n",
        "    plt.title('Receiver Operating Characteristic')\r\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\r\n",
        "    plt.legend(loc = 'lower right')\r\n",
        "    plt.plot([0, 1], [0, 1],'r--')\r\n",
        "    plt.xlim([0, 1])\r\n",
        "    plt.ylim([0, 1])\r\n",
        "    plt.ylabel('True Positive Rate')\r\n",
        "    plt.xlabel('False Positive Rate')\r\n",
        "    plt.show()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxABXQLMca18"
      },
      "source": [
        "probs = bert_predict(bert_classifier, val_dataloader)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "QqpoJ_r4jY7S",
        "outputId": "23e7581f-41cf-4829-ba91-f0ebaf215266"
      },
      "source": [
        "evaluate_roc(probs, y_val)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.9994\n",
            "Accuracy: 99.60%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPWWdIHk_9Ic"
      },
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5koqyzY49C6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30a3bcc-7ea6-4268-8d93-ad2559ff30fa"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "preds = probs[:, 1]\r\n",
        "y_pred = np.where(preds >= 0.5, 1, 0)\r\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       379\n",
            "           1       0.99      0.99      0.99       126\n",
            "\n",
            "    accuracy                           1.00       505\n",
            "   macro avg       0.99      0.99      0.99       505\n",
            "weighted avg       1.00      1.00      1.00       505\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXvA2rakAEH3",
        "outputId": "46912aa8-8b8d-426e-b149-35a40f98039f"
      },
      "source": [
        "print(f1_score(y_val,y_pred))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9920634920634921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFRWqrXDfriw",
        "outputId": "2bcb6428-b5b9-4d0b-9411-dde02b36a6fd"
      },
      "source": [
        "print(confusion_matrix(y_val,y_pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[378   1]\n",
            " [  1 125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc9IfmcPfE0k"
      },
      "source": [
        "vnewtweet.loc[:,'predicted_value'] = y_pred"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b3AxnQMgZ5d"
      },
      "source": [
        "wrongPred = vnewtweet[vnewtweet['Mobile_Tech_Flag'] != vnewtweet['predicted_value']]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Otlv2ETv-XSr",
        "outputId": "d4129bd4-714b-4bf0-a5db-a90c44d6f78f"
      },
      "source": [
        "wrongPred"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>predicted_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>tweet_0827</td>\n",
              "      <td>#NowPlaying The Bottle by Joe Bataan! Find us ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>tweet_3804</td>\n",
              "      <td>पोर्ट्रोनिक्स ने फिंगरप्रिंट सेंसर के साथ स्मा...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Text_ID  ... predicted_value\n",
              "299  tweet_0827  ...               1\n",
              "457  tweet_3804  ...               0\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pejjHm93gkAM",
        "outputId": "b032c79c-aa3e-487d-a00e-7af12e7573e5"
      },
      "source": [
        "for i in range(len(wrongPred)):\r\n",
        "  print(f'Text number {i} :',wrongPred.iloc[i,1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text number 0 : #NowPlaying The Bottle by Joe Bataan! Find us at CRR App: Google Play Apple Micro-site: Web Page #Funk #DiscoMusic #Oldies #70s #DiscoNights #OldiesButGoodies\n",
            "Text number 1 : पोर्ट्रोनिक्स ने फिंगरप्रिंट सेंसर के साथ स्मार्ट होम के लिए बायोलॉक का परिचय दिया - पोर्ट्रोनिक्स ने लॉन्च किया स्मार्टफ़ोन, कैमरा से ओपनगा, 30 मिनट की चार्जिंग में 6 महीने की रिमगी बैटरी -\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9szjTE4ChGSp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}