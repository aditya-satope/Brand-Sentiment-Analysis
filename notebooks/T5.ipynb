{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mockdata/final_data1.pickle\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import re\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/kaggle/working')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import re\n",
    "#\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from rouge import Rouge\n",
    "\n",
    "import pickle\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "file=open('/kaggle/input/mockdata/final_data1.pickle','rb')\n",
    "data=pickle.load(file)\n",
    "random.shuffle(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hindi news happylife if you want to reduce the risk of cancer, drink green tea, it increases the protein in the body that kills cancer cells. Fed up with ads? Install for news without ads Dainik Bhaskar App New Research: If you want to reduce the risk of cancer, drink green-tea, it increases such protein in the body.\\n',\n",
       " 'New research: If you want to reduce the risk of cancer, drink green-tea, it increases the protein in the body that kills the cancer cells.\\n',\n",
       " '0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_article(article):\n",
    "    article = re.sub(r\"http\\S+\", \"\", article)\n",
    "    article = re.sub(r\"www.\\S+\", \"\", article)\n",
    "    article = re.sub(r\"<\\S+\", \"\", article)\n",
    "    #article = re.sub('[.]\\n?', \". \",article)\n",
    "    #article = re.sub(r'[^\\w\\s]', '', article) \n",
    "    article = re.sub('\\n+', \" \",article)\n",
    "    article = article.strip()\n",
    "    #if len(article) > 60:\n",
    "    #    article = article[:-60]\n",
    "    return article\n",
    "#print(preprocess_article(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c8680d26034e0f897b465214ad915a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad9fc0ef8f548dd8208a2b0c0e6adf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8905b4f319964e0ebd050ba4d956e008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for line in data:\n",
    "        line[0]= preprocess_article(line[0].lstrip().rstrip().lower())\n",
    "        line[1]= preprocess_article(line[1].lstrip().rstrip().lower())\n",
    "data_train=data[:3000]\n",
    "data_val=data[3000:]\n",
    "\n",
    "\n",
    "model=T5ForConditionalGeneration.from_pretrained('t5-base').cuda()\n",
    "tokenizer=T5Tokenizer.from_pretrained('t5-base')\n",
    "rouge1=Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge(sentence,ref):\n",
    "    s=''\n",
    "    flag=0\n",
    "    for char in sentence:\n",
    "        if char=='<':\n",
    "            flag=1\n",
    "        elif char=='>':\n",
    "            flag=0\n",
    "        elif flag==0:\n",
    "            s+=char\n",
    "\n",
    "    gen=re.sub('\\s+',' ',s).rstrip().lstrip()\n",
    "#     print(gen)\n",
    "    if gen=='':\n",
    "        return 0,0,0\n",
    "    rg=rouge1.get_scores(gen,ref)\n",
    "    r1,r2,rl=rg[0][\"rouge-1\"]['f'], \\\n",
    "    rg[0][\"rouge-2\"]['f'],rg[0][\"rouge-l\"]['f']\n",
    "    \n",
    "    return r1,r2,rl\n",
    "\n",
    "def generate_batch(data):\n",
    "    output=random.sample(data,4)\n",
    "\n",
    "    inp,label=[],[]\n",
    "    for dat in output:\n",
    "            inp.append(dat[0])\n",
    "            label.append(dat[1])\n",
    "            \n",
    "    return inp,label\n",
    "def val(dev_data):\n",
    "\n",
    "    r1_,r2_,rl_=0,0,0\n",
    "    candidate_corpus,references_corpus=[],[]\n",
    "\n",
    "    for line in dev_data:\n",
    "        inp,label=[line[0]],[line[1]]\n",
    "        input=tokenizer.prepare_seq2seq_batch(src_texts=inp,\n",
    "                                              tgt_texts=label, padding=True, return_tensors='pt')\n",
    "        \n",
    "        output=model.generate(input_ids=input['input_ids'].cuda(),\n",
    "                              num_beams=5, early_stopping=True, max_length=20)\n",
    "        out=tokenizer.batch_decode(output)\n",
    "        out[0] = re.sub(r\"<\\S+\", \"\", out[0])\n",
    "        \n",
    "        candidate_corpus.append(tokenizer.tokenize(out[0]))\n",
    "        references_corpus.append([tokenizer.tokenize(label[0])])\n",
    "\n",
    "        r1,r2,rl=rouge(out[0],line[1])\n",
    "        r1_+=r1\n",
    "        r2_+=r2\n",
    "        rl_+=rl\n",
    "\n",
    "    r1_/=(len(dev_data)*0.01)\n",
    "    r2_/=(len(dev_data)*0.01)\n",
    "    rl_/=(len(dev_data)*0.01)\n",
    "    bleu=0\n",
    "    bleu=100*bleu_score(candidate_corpus, references_corpus)\n",
    "\n",
    "    return r1_,r2_,rl_,bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=50, training loss=1.0169041705131532\n",
      "iteration=100, training loss=0.6731205302476883\n",
      "iteration=150, training loss=0.6208210551738739\n",
      "iteration=200, training loss=0.5606093782186509\n",
      "iteration=250, training loss=0.5213078415393829\n",
      "iteration=300, training loss=0.48459365040063856\n",
      "iteration=350, training loss=0.5068568247556686\n",
      "iteration=400, training loss=0.45633628994226455\n",
      "iteration=450, training loss=0.47629580825567247\n",
      "iteration=500, training loss=0.44122555434703825\n",
      "iteration=550, training loss=0.4272786337137222\n",
      "iteration=600, training loss=0.460400798022747\n",
      "iteration=650, training loss=0.45351127684116366\n",
      "iteration=700, training loss=0.4632643106579781\n",
      "iteration=750, training loss=0.4120591467618942\n",
      "iteration=800, training loss=0.4207980468869209\n",
      "iteration=850, training loss=0.4307216280698776\n",
      "iteration=900, training loss=0.41163205742836\n",
      "iteration=950, training loss=0.42135584145784377\n",
      "iteration=1000, training loss=0.4236678838729858\n",
      "iteration=1050, training loss=0.3782649807631969\n",
      "iteration=1100, training loss=0.399742601364851\n",
      "iteration=1150, training loss=0.4137609227001667\n",
      "iteration=1200, training loss=0.38385830640792845\n",
      "iteration=1250, training loss=0.37776803016662597\n",
      "iteration=1300, training loss=0.36064165115356445\n",
      "iteration=1350, training loss=0.34379186868667605\n",
      "iteration=1400, training loss=0.3343791800737381\n",
      "iteration=1450, training loss=0.35215961173176763\n",
      "iteration=1500, training loss=0.3687101635336876\n",
      "iteration=1550, training loss=0.3557976222038269\n",
      "iteration=1600, training loss=0.34946330279111865\n",
      "iteration=1650, training loss=0.36848728597164154\n",
      "iteration=1700, training loss=0.35328827545046804\n",
      "iteration=1750, training loss=0.3716648103296757\n",
      "iteration=1800, training loss=0.34270259536802766\n",
      "iteration=1850, training loss=0.34400131821632385\n",
      "iteration=1900, training loss=0.3516361936926842\n",
      "iteration=1950, training loss=0.34039330229163167\n",
      "iteration=2000, training loss=0.3108784732222557\n",
      "validation BLEU=24.638438689696816, validation R1=33.72290508999156, validation R2=21.62799906129066, validation RL=33.60887101777643\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer=optim.AdamW(model.parameters(),lr=0.00002)\n",
    "\n",
    "scalar=0\n",
    "val_score=0\n",
    "for i in range(2000):\n",
    "        model.train()\n",
    "        inp,label=generate_batch(data_train)\n",
    "        input=tokenizer.prepare_seq2seq_batch(src_texts=inp, tgt_texts=label, padding=True, return_tensors='pt',max_length=600,truncation=True)\n",
    "        outputs=model(input_ids=input['input_ids'].cuda(),labels=input['labels'].cuda())\n",
    "        loss=outputs[0]\n",
    "\n",
    "        scalar+=loss.item()\n",
    "        if(i+1)%50==0:\n",
    "                print('iteration={}, training loss={}'.format(i+1,scalar/(4*50)))\n",
    "                scalar=0\n",
    "        if(i+1)%2000==0:\n",
    "                r1,r2,rl,bleu=val(data_val)\n",
    "                print('validation BLEU={}, validation R1={}, validation R2={}, validation RL={}'.format(bleu,r1,r2,rl))\n",
    "                \n",
    "                \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-0.4.1.2.tar.gz (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.2.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.55.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (0.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.11.13)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.9.4)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.43)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-py3-none-any.whl size=103066 sha256=ee2da78711cb40e3e64cc4af95a3e961b5460b6a49d30c3438c50b103d2c8b44\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/a2/db/5d9e7c4aa8dbd82718c202fb1bc7118c2d3bf0925af92943f2\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-0.4.1.2\n",
      "Collecting rouge\n",
      "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from rouge) (1.15.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install -U rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation BLEU=22.70092736806129, validation R1=33.47478494404291, validation R2=21.31588646212235, validation RL=32.48059324320051\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data_val = data[3000:3500]\n",
    "r1,r2,rl,bleu=val(data_val)\n",
    "print('validation BLEU={}, validation R1={}, validation R2={}, validation RL={}'.format(bleu,r1,r2,rl))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = []\n",
    "for row in data_val:\n",
    "    \n",
    "    if row[2]=='1':\n",
    "        data_x.append(row)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOBILE THEME VALIDATION ARTICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation BLEU=23.32314254925191, validation R1=29.971884569561293, validation R2=16.572101959069425, validation RL=30.019844323844747\n"
     ]
    }
   ],
   "source": [
    "r1,r2,rl,bleu=val(data_x)\n",
    "print('validation BLEU={}, validation R1={}, validation R2={}, validation RL={}'.format(bleu,r1,r2,rl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'modelt5_.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
