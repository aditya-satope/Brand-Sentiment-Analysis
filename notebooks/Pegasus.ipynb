{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install sentencepiece","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchtext","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install rouge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfile=open('../input/final-data1/final_data1.pickle','rb')\nimport pickle\ndata=pickle.load(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for row in data:\n        row[0]=row[0].lstrip().rstrip().lower()\n        row[1]=row[1].lstrip().rstrip().lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.shuffle(data)\n\nimport torch.optim as optim\nimport torch\n\nimport re\n\nfrom torchtext.data.metrics import bleu_score\nfrom rouge import Rouge\n\n# from transformers import MT5ForConditionalGeneration, T5Tokenizer\n\n# model=MT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\").cuda()\n# tokenizer=T5Tokenizer.from_pretrained(\"google/mt5-small\")\n\nfrom transformers import PegasusTokenizer, PegasusForConditionalGeneration\n\nmodel = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum').cuda()\ntokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n\n\ndata_train=data[:3000]\ndata_val=data[3000:3500]\n\nrouge1=Rouge()\n\ndef rouge(sentence,ref):\n    s=''\n    flag=0\n    for char in sentence:\n        if char=='<':\n            flag=1\n        elif char=='>':\n            flag=0\n        elif flag==0:\n            s+=char\n\n    gen=re.sub('\\s+',' ',s).rstrip().lstrip()\n#     print(gen)\n    if gen=='':\n        return 0,0,0\n    rg=rouge1.get_scores(gen,ref)\n    r1,r2,rl=rg[0][\"rouge-1\"]['f'], \\\n    rg[0][\"rouge-2\"]['f'],rg[0][\"rouge-l\"]['f']\n    \n    return r1,r2,rl\n\ndef val(dev_data):\n\n    r1_,r2_,rl_=0,0,0\n    candidate_corpus,references_corpus=[],[]\n\n    for line in dev_data:\n        inp,label=[line[0]],[line[1]]\n        input=tokenizer.prepare_seq2seq_batch(src_texts=inp,\n                                              tgt_texts=label, padding=True, return_tensors='pt')\n        \n        output=model.generate(input_ids=input['input_ids'].cuda(),\n                              num_beams=5, early_stopping=True, max_length=20)\n        out=tokenizer.batch_decode(output)\n#         print(out)\n        candidate_corpus.append(tokenizer.tokenize(out[0]))\n        references_corpus.append([tokenizer.tokenize(label[0])])\n\n        r1,r2,rl=rouge(out[0],line[1])\n        r1_+=r1\n        r2_+=r2\n        rl_+=rl\n\n    r1_/=(len(dev_data)*0.01)\n    r2_/=(len(dev_data)*0.01)\n    rl_/=(len(dev_data)*0.01)\n    bleu=0\n    bleu=100*bleu_score(candidate_corpus, references_corpus)\n\n    return r1_,r2_,rl_,bleu\n\n# def generate_batch(data):\n#     output=random.sample(data,4)\n#     inp,label=[],[]\n#     for dat in output:\n#             inp.append(dat[0])\n#             label.append(dat[1])\n            \n#     return inp,label\n\n# optimizer=optim.AdamW(model.parameters(),lr=0.00004)\n\n# scalar=0\n# val_score=0\n# for i in range(2000):\n#         model.train()\n#         inp,label=generate_batch(data_train)\n#         input=tokenizer.prepare_seq2seq_batch(src_texts=inp,\n#                                               tgt_texts=label, padding=True, return_tensors='pt',max_length=300,truncation=True)\n#         outputs=model(input_ids=input['input_ids'].cuda(),labels=input['labels'].cuda())\n#         loss=outputs[0]\n\n#         scalar+=loss.item()\n#         if(i+1)%50==0:\n#                 print('iteration={}, training loss={}'.format(i+1,scalar/(4*50)))\n#                 scalar=0\n# #         if(i+1)%2000==0:\n# #                  r1,r2,rl,bleu=val(data_val)\n# #                  print('validation BLEU={}, validation R1={}, validation R2={}, validation RL={}'.format(bleu,r1,r2,rl))\n                \n# #                  torch.save(model.state_dict(),'model_.pth')\n\n#         loss.backward()\n#         optimizer.step()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(),'model_p.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('./model_p.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r1,r2,rl,bleu=val(data_val)\nprint(r1,r2,rl,bleu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}